{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Бич-трэвел\". Описание проекта.\n",
    "\n",
    "**Краткое описание.** Как известно, перемещения внутри Европы зачастую очень дешёвые (легко найти билеты лоукостеров вроде RyanAir за 6-10 евро или доехать на автобусе). Однако поисковики авиабилетов не предоставляют опции (во всяком случае, у меня не получилось найти) поиска маршрутов с разными промежуточными городами (только если заранее знать эти города, что не совсем наш случай). \n",
    "\n",
    "Моей задачей было сделать программу которая ищет комбинированные перелёты, пользуясь спец.предложениями величайшей российской авиакомпании (Победа) и предлагает самые дешёвые из них. Программа подойдёт тем, кому принципиальна цена путешествия или просто тем, кто любит путешествовать по Европе (но впрочем, никто не мешает запустить программу для какого-нибудь российского города) без какой-то конкретной цели.\n",
    "\n",
    "**Программа состоит из трёх частей.**\n",
    "1. Первая часть ищет комбинированные перелёты на сайте Победы. Замечу сразу, что эта часть является нестабильной, потому что спецпредложения постоянно меняют (по неизвестному мне принципу) и то, что работает сегодня, может спокойно не работать завтра. Поэтому не стоит сильно расстраиваться, если вдруг программа выдала, что комбинаций перелётов не найдено. Это скорее всего значит не то, что программа не работает, а то, что сегодня не ваш (и не мой) день. *На момент начала проекта Победа искала до конца мая. На момент сдачи проекта (15.04), Победа адекватно ищет только до конца апреля. Возможно, на момент проверки станет получше, но ничего гарантировать, как вы понимаете, не могу.*\n",
    "2. Вторая часть ищет самую дешёвую комбинацию из двух прямых перелётов в город назначения с помощью сайта Aviasales и выводит самый дешёвый вариант на выбранные вами даты. Тут так же стоит заметить, что Авиасейлс может выдавать разные цены для разных пользователей (что как-то странно, но проверено мной при отладке программы), поэтому не могу дать гарантии, что если вы потом захотите купить эти билеты, то их стоимость будет в точности совпадать с озвученной программой (но отличаться, впрочем, будет несильно). *Если вы ввели город, в который в какие-то из дней нет перелётов, то программа может работать некорректно, так как данные о цене не берутся численно (чисел в графике на сайте нигде нет), а высчитываются из высоты столбцов, поэтому в данных появятся несуществующие низкие цены.*\n",
    "3. Третья (бонусная) часть выдаёт вам погоду (потому что это прикольно и потому что мне нужно было побольше использовать API) в месте вашего путешествия (было решено, что репрезентативнее будет выдавать не текущую погоду, а погоду предыдущего года в даты предлагаемого путешествия), а также содержит анализ и размышления о корреляции стоимости билетов и времени до вылета.\n",
    "\n",
    "**Размышления о корреляции.**\n",
    "Существует довольно известное утверждение, что при формировании цен на билеты авиакомпании осуществляют ценовую дискриминацию, повышая стоимость билетов по мере приближения к дате вылета. Пользуясь случаем, было решено проверить, насколько сильно коррелирует стоимость билетов с количеством дней, оставшихся до вылета (по предположению, корреляция должна была быть близка к -1). Однако, в большинстве случаев, если брать данные с апреля до октября-ноября, то корреляция близка к нулю. Но если брать 30-, а ещё лучше 10-дневный период от текущей даты, то предполагавшаяся обратная зависимость действительно присутствует.\n",
    "\n",
    "**За что можно поставить баллы?**\n",
    "Для удобства оценивания, все функции в файле с программой расположены в алфавитном порядке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "Датафреймы используются в первой части для реализации алгоритма поиска самых дешёвых комбинаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-efad93aca2b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# из main()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mpos_flights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Откуда'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Куда'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Цена'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Дата'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mairports\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mpos_flights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos_flights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflights_city\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_fl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def flights_city(city, all_fl):\n",
    "    res = pd.concat([all_fl[all_fl['Откуда'] == city], all_fl[all_fl['Куда'] == city]], ignore_index = True)\n",
    "    return res\n",
    "\n",
    "def get_all_flights(page):\n",
    "    all_flights = pd.DataFrame(columns = ['Откуда', 'Куда', 'Цена', 'Дата'])\n",
    "    for f in page.findAll('li', class_ = 'airtickets-item clearfix'):\n",
    "        flight = str(f.find('div', class_ = 'airtickets-cities'))\n",
    "        flight = flight.strip('<div class=\"airtickets-cities\"></')\n",
    "        flight = flight.split('<br/>')\n",
    "        price = int(f.find('div', class_ = 'airtickets-cost').text.strip('руб').replace(' ', ''))\n",
    "        date = f.find('div', class_ = 'airtickets-date').text\n",
    "        date = date_converter(date)\n",
    "        if len(flight) == 2:\n",
    "            fl_info = pd.DataFrame([[flight[0], flight[1], price, date]], columns = ['Откуда', 'Куда', 'Цена', 'Дата'])\n",
    "            all_flights = pd.concat([all_flights, fl_info], ignore_index = True)\n",
    "    return all_flights\n",
    "\n",
    "# из main()\n",
    "pos_flights = pd.DataFrame(columns = ['Откуда', 'Куда', 'Цена', 'Дата'])\n",
    "for air in airports:\n",
    "    pos_flights = pd.concat([pos_flights, flights_city(air, all_fl)], ignore_index = True)\n",
    "pos_flights = flights_city('Москва (Внуково)', pos_flights)\n",
    "fl_first = pos_flights[pos_flights['Откуда'] == 'Москва (Внуково)']\n",
    "fl_second = pos_flights[pos_flights['Куда'] == 'Москва (Внуково)']\n",
    "\n",
    "comb = fl_first.merge(fl_second, left_on = 'Откуда', right_on = 'Куда')\n",
    "comb = comb[comb['Дата_y'].apply(toord) - comb['Дата_x'].apply(toord) >= min_spot]\n",
    "comb = comb[comb['Дата_y'].apply(toord) - comb['Дата_x'].apply(toord) <= max_spot]\n",
    "comb['Итоговая цена'] = comb['Цена_x'] + comb['Цена_y']\n",
    "comb = comb.sort_values(by = 'Итоговая цена')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Веб-скреппинг\n",
    "В большом количестве использовался BeautifulSoup. Используется selenium для получения информации с сайта Победы (который весь меняется динамически без перехода на другую страницу) и для обхода защиты баз 2004 года, но более содержательное использование для получения графика всех цен с Aviasales. Ну и главное детище (которое, к сожалению, так и не удалось доработать до конца, но которое всё равно выглядит довольно внушительно): кликание по датам на сайте Победы (функция pobeda_class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_russian(c):\n",
    "    r = requests.get('http://www.avia-shop.ru/codes.phtml?country=RU')\n",
    "    page = BeautifulSoup(r.text, features = 'html')\n",
    "    body = page.findAll('table')[9]\n",
    "    for i in body.findAll('tr'):\n",
    "        if i.find('td').text.split()[0] == c:\n",
    "            return i.find('td').text.split()[1].strip('()')\n",
    "    return '404'\n",
    "\n",
    "def generate_coordinates(page):\n",
    "    cities = page.findAll('div', class_ = 'form-dropoutList')[1]\n",
    "    all_cities = []\n",
    "    for c in cities.findAll('div', class_ = 'form-dropoutList__item'):\n",
    "        city = c.text.strip()\n",
    "        req = requests.get('https://geocode-maps.yandex.ru/1.x/?geocode=' + city)\n",
    "        page_city = BeautifulSoup(req.text, features = 'xml')\n",
    "        coords = page_city.Point.pos.text.split()\n",
    "        coords[0] = float(coords[0])\n",
    "        coords[1] = float(coords[1])\n",
    "        all_cities.append([city, coords])\n",
    "    return all_cities\n",
    "\n",
    "def get_airport_code(c):\n",
    "    browser = webdriver.Chrome('C:\\Program Files\\chromedriver.exe')\n",
    "    browser.get('http://www.aviation.com.ua/sirena/goroda.htm')\n",
    "    bs = BeautifulSoup(browser.page_source)\n",
    "    browser.close()\n",
    "    all_air = bs.findAll('pre')[2].text.split('\\n')[0:1022]\n",
    "    res = []\n",
    "    for city in all_air:\n",
    "        city = city.split('\\t')\n",
    "        if city[1].count(c) > 0:\n",
    "            res.append(city)\n",
    "    if len(res) == 0:\n",
    "        check = check_russian(c)\n",
    "        if check == '404':\n",
    "            return '404'\n",
    "        else:\n",
    "            return check\n",
    "    else:\n",
    "        res.sort(key = second_elem)\n",
    "        return res[0][0]\n",
    "\n",
    "def get_all_flights(page):\n",
    "    all_flights = pd.DataFrame(columns = ['Откуда', 'Куда', 'Цена', 'Дата'])\n",
    "    for f in page.findAll('li', class_ = 'airtickets-item clearfix'):\n",
    "        flight = str(f.find('div', class_ = 'airtickets-cities'))\n",
    "        flight = flight.strip('<div class=\"airtickets-cities\"></')\n",
    "        flight = flight.split('<br/>')\n",
    "        price = int(f.find('div', class_ = 'airtickets-cost').text.strip('руб').replace(' ', ''))\n",
    "        date = f.find('div', class_ = 'airtickets-date').text\n",
    "        date = date_converter(date)\n",
    "        if len(flight) == 2:\n",
    "            fl_info = pd.DataFrame([[flight[0], flight[1], price, date]], columns = ['Откуда', 'Куда', 'Цена', 'Дата'])\n",
    "            all_flights = pd.concat([all_flights, fl_info], ignore_index = True)\n",
    "    return all_flights\n",
    "\n",
    "def get_graph(code1, code2, d1):\n",
    "    browser = webdriver.Chrome('C:\\Program Files\\chromedriver.exe')\n",
    "    browser.get('https://www.aviasales.ru/search/' + code1 + d1 + code2 + '1')\n",
    "    time.sleep(20)\n",
    "    exp = browser.find_element_by_class_name('prediction-header__expand-button')\n",
    "    exp.click()\n",
    "    time.sleep(2)\n",
    "    switch = browser.find_elements_by_class_name('calendar-type-switcher__item')[1]\n",
    "    switch.click()\n",
    "    time.sleep(2)\n",
    "    bs = BeautifulSoup(browser.page_source)\n",
    "    browser.close()\n",
    "    pr = bs.find('div', class_ = 'graph__y-item', style = 'top: 0%;')\n",
    "    max_price = int(pr.find('span').text.replace('\\u2009', ''))\n",
    "    graph = bs.find('svg', class_ = 'graph__axis-x')\n",
    "    prices = []\n",
    "    for rec in graph.findAll('rect')[1:750:3]:\n",
    "        prices.append(int((100 - float(rec['height'].strip('%'))) * max_price / 100))\n",
    "    return prices\n",
    "\n",
    "def pobeda_class():\n",
    "    browser = webdriver.Chrome('C:\\Program Files\\chromedriver.exe')\n",
    "    browser.get('https://www.pobeda.aero/information/book/search_cheap_tickets')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    date_from = browser.find_element_by_name('date_departure_from')\n",
    "    date_to = browser.find_element_by_name('date_departure_to')\n",
    "    date_from.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    bs = BeautifulSoup(browser.page_source)\n",
    "    ident = bs.find('div', class_ = 'header-form__calendar hasDatepicker')['id']\n",
    "    ident = '\"dp' + str(int(ident.strip('dp')) + 10) + '\"'\n",
    "    \n",
    "    today = datetime.now().date()\n",
    "    num_clicks = d1.month - today.month\n",
    "    \n",
    "    for i in range(num_clicks):\n",
    "        browser.find_element_by_xpath('//*[@id='+ ident +']/div[1]/div[2]/div/a').click()\n",
    "    \n",
    "    browser.find_element_by_xpath('//*[@id='+ ident +']/div[1]/div[1]/table/tbody//*[text()=\"' + str(d1.day) + '\"]').click()\n",
    "    time.sleep(5)\n",
    "    elem = browser.find_element_by_xpath('//*[@id='+ ident +']')\n",
    "    ref = elem.get_attribute('outerHTML')\n",
    "    mon = ref.split('data-end=')[1].split()[0]\n",
    "    mon = int(mon.split('.')[1])\n",
    "    if mon - int(d2.month) < 0:\n",
    "        for i in range(int(d2.month) - mon + 1):\n",
    "            browser.find_element_by_xpath('//*[@id='+ ident +']/div[1]/div[2]/div/a').click()\n",
    "    elif mon - int(d2.month) > 0:\n",
    "        for i in range(mon - int(d2.month) + 1):\n",
    "            browser.find_element_by_xpath('//*[@id='+ ident +']/div[1]/div[1]/div/a').click()\n",
    "    browser.find_element_by_xpath('//*[@id='+ ident +']/div[1]/div[1]/table/tbody//*[text()=\"' + str(d2.day) + '\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API\n",
    "API использовался для получения координат городов (как в домашке, через геокодер яндекса) и для делания всяких прикольных штук с погодой через API MetaWeather (включая вывод соответствующей картинки с погодой)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coordinates(page):\n",
    "    cities = page.findAll('div', class_ = 'form-dropoutList')[1]\n",
    "    all_cities = []\n",
    "    for c in cities.findAll('div', class_ = 'form-dropoutList__item'):\n",
    "        city = c.text.strip()\n",
    "        req = requests.get('https://geocode-maps.yandex.ru/1.x/?geocode=' + city)\n",
    "        page_city = BeautifulSoup(req.text, features = 'xml')\n",
    "        coords = page_city.Point.pos.text.split()\n",
    "        coords[0] = float(coords[0])\n",
    "        coords[1] = float(coords[1])\n",
    "        all_cities.append([city, coords])\n",
    "    return all_cities\n",
    "\n",
    "def get_coord(city):\n",
    "    req = requests.get('https://geocode-maps.yandex.ru/1.x/?geocode=' + city)\n",
    "    page_city = BeautifulSoup(req.text, features = 'xml')\n",
    "    coords = page_city.Point.pos.text.split()\n",
    "    coords[0] = float(coords[0])\n",
    "    coords[1] = float(coords[1])\n",
    "    return coords\n",
    "\n",
    "def get_woeid(city):\n",
    "    coords = get_coord(city)\n",
    "    params = {'action':'query', 'format': 'json'}\n",
    "    r = requests.get('https://www.metaweather.com/api/location/search/?lattlong=' + str(coords[1])+','+str(coords[0]), params)\n",
    "    res = re.findall(r'\\{[^\\}]+', r.text)[0] + '}'\n",
    "    dic = json.loads(res)\n",
    "    city_eng = dic['title']\n",
    "    woeid = dic['woeid']\n",
    "    return woeid\n",
    "\n",
    "def get_weather(woeid, date):\n",
    "    r1 = requests.get('https://www.metaweather.com/api/location/' + str(woeid) + '/' + str(date.year) + '/' + str(date.month) + '/' + str(date.day))\n",
    "    page = BeautifulSoup(r1.text, features = 'html')\n",
    "    res1 = re.findall(r'\\{[^\\}]+', page.text)[0] + '}'\n",
    "    dic1 = json.loads(res1)\n",
    "    return {'weather': dic1['weather_state_name'], \n",
    "           'pic' : dic1['weather_state_abbr'],\n",
    "           'min_temp' : dic1['min_temp'],\n",
    "           'max_temp' : dic1['max_temp']}\n",
    "\n",
    "def draw_pic(ab):\n",
    "    display(Image(url = 'https://www.metaweather.com/static/img/weather/png/' + ab + '.png', width = 50, height = 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация\n",
    "Красивые графики, построенные с помощью iplot в сочетании с cufflinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prices(p1, p2, min_date, p1_full):\n",
    "    init_notebook_mode()\n",
    "    cufflinks.go_offline()\n",
    "    \n",
    "    t = [0] * len(p1)\n",
    "    for i in range(len(p1)):\n",
    "        t[i] = datetime.fromordinal(min_date.toordinal() + i).date()\n",
    "    d1 = pd.Series(p1, index = t)\n",
    "    d2 = pd.Series(p2, index = t)\n",
    "    data = pd.DataFrame([d1, d2], index = ['Из Москвы', 'В Москву']).transpose()\n",
    "    \n",
    "    data[['Из Москвы', 'В Москву']].iplot(kind = 'bar', barmode = 'overlay', xTitle='Дата',\n",
    "                                          yTitle='Стоимость билета (в рублях)', title = 'График стоимости билетов')\n",
    "\n",
    "    bins = np.arange(0, len(p1_full))\n",
    "    p1 = np.array(p1)\n",
    "    mean_1 = int(np.mean(p1))\n",
    "    median_1 = np.median(p1)\n",
    "    corr_1 = scst.pearsonr(p1_full, bins)[0]\n",
    "    corr_2 = scst.pearsonr(p1_full[0:30], bins[0:30])[0]\n",
    "    corr_3 = scst.pearsonr(p1_full[0:10], bins[0:10])[0]\n",
    "    print('Немного статистики по стоимости билетов из Москвы в город назначения:')\n",
    "    print('Средняя стоимость билетов: ' + str(mean_1) + ' рублей, медианная стоимость: ' + str(median_1) + ' рублей')\n",
    "    print('\\nЛогично предположить, что цена билета должна отрицательно зависеть от количества дней до отправления.')\n",
    "    print('Давайте проверим эту гипотезу, посчитав коэффициент корреляции')\n",
    "    print('Коэффициент корреляции (для всех цен): ' + str(corr_1))\n",
    "    print('Коэффициент корреляции (для вылета в течение 30 ближайших дней): ' + str(corr_2))\n",
    "    print('Коэффициент корреляции (для вылета в течение 10 ближайших дней): ' + str(corr_3))\n",
    "    print('Размышления о корреляции можно найти в описании проекта.')\n",
    "    \n",
    "    data['Из Москвы'].iplot(kind = 'hist', xTitle='Стоимость билета (в рублях)',\n",
    "                                          yTitle='Кол-во дней с самым дешёвым билетом по данной цене', \n",
    "                                          title = 'Распределение стоимости билетов из Москвы в город назначения')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Математика\n",
    "Использовались массивы numpy для оптимизации алгоритма по вычислению расстояния между двумя точками на сфере и scipy.stats для проведения небольшого исследования о корреляции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(coord1, coord2):\n",
    "    rad = 6371 * 1000\n",
    "    \n",
    "    coords = np.array([coord1[1], coord2[1], coord1[0], coord2[0]])\n",
    "    coords = coords * math.pi/180\n",
    "    \n",
    "    delta_long = coords[3] - coords[2]\n",
    "    \n",
    "    lat = coords.copy()\n",
    "    lat[0:2] = np.cos(coords[0:2]).copy()\n",
    "    lat[2:4] = np.sin(coords[0:2]).copy()\n",
    "    \n",
    "    nom = math.pow(lat[1] * math.sin(delta_long), 2) + math.pow(lat[0] * lat[3] - lat[2] * lat[1] * math.cos(delta_long), 2)\n",
    "    nom = math.sqrt(nom)\n",
    "    den = lat[2] * lat[3] + lat[0] * lat[1] * math.cos(delta_long)\n",
    "    angle_dif = math.atan2(nom, den)\n",
    "    return angle_dif * rad\n",
    "\n",
    "def plot_prices(p1, p2, min_date, p1_full):\n",
    "    init_notebook_mode()\n",
    "    cufflinks.go_offline()\n",
    "    \n",
    "    t = [0] * len(p1)\n",
    "    for i in range(len(p1)):\n",
    "        t[i] = datetime.fromordinal(min_date.toordinal() + i).date()\n",
    "    d1 = pd.Series(p1, index = t)\n",
    "    d2 = pd.Series(p2, index = t)\n",
    "    data = pd.DataFrame([d1, d2], index = ['Из Москвы', 'В Москву']).transpose()\n",
    "    \n",
    "    data[['Из Москвы', 'В Москву']].iplot(kind = 'bar', barmode = 'overlay', xTitle='Дата',\n",
    "                                          yTitle='Стоимость билета (в рублях)', title = 'График стоимости билетов')\n",
    "\n",
    "    bins = np.arange(0, len(p1_full))\n",
    "    p1 = np.array(p1)\n",
    "    mean_1 = int(np.mean(p1))\n",
    "    median_1 = np.median(p1)\n",
    "    corr_1 = scst.pearsonr(p1_full, bins)[0]\n",
    "    corr_2 = scst.pearsonr(p1_full[0:30], bins[0:30])[0]\n",
    "    corr_3 = scst.pearsonr(p1_full[0:10], bins[0:10])[0]\n",
    "    print('Немного статистики по стоимости билетов из Москвы в город назначения:')\n",
    "    print('Средняя стоимость билетов: ' + str(mean_1) + ' рублей, медианная стоимость: ' + str(median_1) + ' рублей')\n",
    "    print('\\nЛогично предположить, что цена билета должна отрицательно зависеть от количества дней до отправления.')\n",
    "    print('Давайте проверим эту гипотезу, посчитав коэффициент корреляции')\n",
    "    print('Коэффициент корреляции (для всех цен): ' + str(corr_1))\n",
    "    print('Коэффициент корреляции (для вылета в течение 30 ближайших дней): ' + str(corr_2))\n",
    "    print('Коэффициент корреляции (для вылета в течение 10 ближайших дней): ' + str(corr_3))\n",
    "    print('Размышления о корреляции можно найти в описании проекта.')\n",
    "    \n",
    "    data['Из Москвы'].iplot(kind = 'hist', xTitle='Стоимость билета (в рублях)',\n",
    "                                          yTitle='Кол-во дней с самым дешёвым билетом по данной цене', \n",
    "                                          title = 'Распределение стоимости билетов из Москвы в город назначения')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Другие технологии\n",
    "Использовались модули Ipython.display (вывод картинок), ipywidgets (виджеты для удобного ввода дат), re (регулярные выражения для более удобной работы с API погоды) и модуль datetime (много работы с датами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pic(ab):\n",
    "    display(Image(url = 'https://www.metaweather.com/static/img/weather/png/' + ab + '.png', width = 50, height = 50))\n",
    "    \n",
    "print(\"Самая ранняя возможная дата отправления?\")\n",
    "widget_start = widgets.DatePicker(description='Отправление', disabled=False)\n",
    "display(widget_start)\n",
    "\n",
    "print(\"Самая поздняя возможная дата прибытия?\")\n",
    "widget_finish = widgets.DatePicker(description='Прибытие', disabled=False)\n",
    "display(widget_finish)\n",
    "\n",
    "def get_weather(woeid, date):\n",
    "    r1 = requests.get('https://www.metaweather.com/api/location/' + str(woeid) + '/' + str(date.year) + '/' + str(date.month) + '/' + str(date.day))\n",
    "    page = BeautifulSoup(r1.text, features = 'html')\n",
    "    res1 = re.findall(r'\\{[^\\}]+', page.text)[0] + '}'\n",
    "    dic1 = json.loads(res1)\n",
    "    return {'weather': dic1['weather_state_name'], \n",
    "           'pic' : dic1['weather_state_abbr'],\n",
    "           'min_temp' : dic1['min_temp'],\n",
    "           'max_temp' : dic1['max_temp']}\n",
    "\n",
    "def get_woeid(city):\n",
    "    coords = get_coord(city)\n",
    "    params = {'action':'query', 'format': 'json'}\n",
    "    r = requests.get('https://www.metaweather.com/api/location/search/?lattlong=' + str(coords[1])+','+str(coords[0]), params)\n",
    "    res = re.findall(r'\\{[^\\}]+', r.text)[0] + '}'\n",
    "    dic = json.loads(res)\n",
    "    city_eng = dic['title']\n",
    "    woeid = dic['woeid']\n",
    "    return woeid\n",
    "\n",
    "def get_best(p1, p2, min_date, max_date, min_spot, max_spot):\n",
    "    delta1 = min_date.toordinal() - datetime.now().date().toordinal()\n",
    "    delta2 = max_date.toordinal() - datetime.now().date().toordinal()\n",
    "    len_p1 = len(p1)\n",
    "    len_p2 = len(p2)\n",
    "    p_min = 1000000\n",
    "    for i in range(delta1, min(len_p1, delta2) - min_spot):\n",
    "        for j in range(min(i + min_spot, len_p2, delta2), min(i + max_spot + 1, len_p2, delta2 + 1)):\n",
    "            if (p1[i] + p2[j] < p_min):\n",
    "                p_min = p1[i] + p2[j]\n",
    "                best = (i, j)\n",
    "    return (p_min, best)\n",
    "\n",
    "def say_res(res):\n",
    "    today = datetime.now().date()\n",
    "    date_start = datetime.date(datetime.fromordinal(today.toordinal() + res[1][0]))\n",
    "    date1 = str(date_start)\n",
    "    date2 = str(datetime.date(datetime.fromordinal(today.toordinal() + res[1][1])))\n",
    "    print('Самый дешёвый вариант прямого путешествия в выбранный вами город:')\n",
    "    print('Цена перелёта: ' + str(res[0]) + ' рублей, Даты: c ' + date1 + ' по ' + date2)\n",
    "    return date_start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
